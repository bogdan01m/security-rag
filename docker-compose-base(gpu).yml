services:

  chroma:
    build:
      context: ./services/sec_rag/chroma
    container_name: chroma
    env_file:
      - .env
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000"]
      interval: 10s
      timeout: 5s
      retries: 3  
    environment:
      - CHROMA_PERSIST_DIRECTORY=${CHROMA_PERSIST_DIRECTORY}
      - OLLAMA_HOST=${OLLAMA_HOST}
      - OLLAMA_PORT=${OLLAMA_PORT}
    ports:
      - "${CHROMA_PORT}:8000"  
    volumes:
      - chroma:/app/chroma_db 
    network_mode: host
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
      
  llm:
    build:
      context: ./services/sec_rag/llm
    container_name: llm_api
    env_file:
      - .env
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001"]
      interval: 10s
      timeout: 5s
      retries: 3    
    environment:
      - MISTRAL_API_KEY=${MISTRAL_API_KEY}
      - CHROMA_HOST=${CHROMA_HOST}
      - CHROMA_PORT=${CHROMA_PORT}
      - OLLAMA_HOST=${OLLAMA_HOST}
      - OLLAMA_PORT=${OLLAMA_PORT}
      - LANGFUSE_SECRET_KEY=${LANGFUSE_SECRET_KEY}
      - LANGFUSE_PUBLIC_KEY=${LANGFUSE_PUBLIC_KEY}
      - LANGFUSE_HOST=${LANGFUSE_HOST}
      - LANGFUSE_PORT=${LANGFUSE_PORT}
    ports:
      - "${LLM_PORT}:8001"  
    depends_on:
      - chroma
    network_mode: host  
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

    
volumes:
  chroma:

